{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd5256c",
   "metadata": {},
   "source": [
    "#### In this notebook, a simple feed forward network is trained using graph neural networks to predict energies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b2c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df5ac9a3",
   "metadata": {},
   "source": [
    "#### Import some required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "## For some analysis\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis import distances\n",
    "\n",
    "## For plotting\n",
    "import matplotlib as mpl\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "## For visualization\n",
    "import nglview as nv\n",
    "\n",
    "## For some data pre-processing\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "## For neural network training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import torch.nn.functional as Fun\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f192e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39ae26e3",
   "metadata": {},
   "source": [
    "#### Global matplot font settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93479017",
   "metadata": {},
   "outputs": [],
   "source": [
    "showPlots=1\n",
    "useMagics=1\n",
    "if useMagics:\n",
    "    %matplotlib inline\n",
    "    #%matplotlib notebook\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reload_ext autoreload\n",
    "    \n",
    "font = {'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3263b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0037b2f5",
   "metadata": {},
   "source": [
    "#### Read positions and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Sorted universe \n",
    "\n",
    "print('Creating a MD analysis universe from the given structure') \n",
    "sorted_isomers_universe = mda.Universe(\"data/isomers_formatted.xyz\")\n",
    "\n",
    "print('Universe created.')\n",
    "\n",
    "print(f'Number of structures in the given file: {sorted_isomers_universe.trajectory.n_frames}')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pbe_energies = pd.read_csv('data/energies.txt', \n",
    "                           comment=\"#\", \n",
    "                           names=['structure', 'energy'], \n",
    "                           delim_whitespace=True)\n",
    "\n",
    "    \n",
    "# Scale output energies to the range -1 to 1.\n",
    "y_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "#y_scaler = preprocessing.StandardScaler()\n",
    "y_scaler.fit(pbe_energies.energy.values.reshape(-1,1))\n",
    "y_scaled = y_scaler.transform(pbe_energies.energy.values.reshape(-1,1))\n",
    "y_scaled = np.array(y_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada5828-c190-4cf5-9a17-c41599debf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d51592-e9ff-44ad-8770-3d14fc2099e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE,CREDITS: https://projects.volkamerlab.org/teachopencadd/talktorials/T036_e3_equivariant_gnn.html\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_point_cloud_3d(\n",
    "    fig: mpl.figure.Figure,\n",
    "    ax_pos: int,\n",
    "    color: np.ndarray,\n",
    "    pos: np.ndarray,\n",
    "    cmap: str = \"plasma\",\n",
    "    point_size: float = 180.0,\n",
    "    label_axes: bool = False,\n",
    "    annotations: list = None,\n",
    "    annotate_points: bool = True,\n",
    "    remove_axes_ticks: bool = True,\n",
    "    cbar_label: str = \"\",\n",
    "    cbar: bool = False\n",
    ") -> mpl.axis.Axis:\n",
    "    \"\"\"Visualize colored 3D point clouds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig : mpl.figure.Figure\n",
    "        The figure for which a new axis object is added for plotting\n",
    "    ax_pos : int\n",
    "        Three-digit integer specifying axis layout and position\n",
    "        (see docs for `mpl.figure.Figure.add_subplot`)\n",
    "    color : np.ndarray\n",
    "        The point colors as a float array of shape `(N,)`\n",
    "    pos : np.ndarray\n",
    "        The point xyz-coordinates as an array\n",
    "    cmap : str, optional\n",
    "        String identifier for a matplotlib colormap.\n",
    "        Is used to map the values in `color` to rgb colors.\n",
    "        , by default \"plasma\"\n",
    "    point_size : float, optional\n",
    "        The size of plotted points, by default 180.0\n",
    "    label_axes : bool, optional\n",
    "        whether to label x,y and z axes by default False\n",
    "    annotations: list, optional\n",
    "        annotations for annotating each node.\n",
    "    annotate_points : bool, optional\n",
    "        whether to label points with their index, by default True\n",
    "    cbar_label : str, optional\n",
    "        label for the colorbar, by default \"\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mpl.axis.Axis\n",
    "        The new axis object for the 3D point cloud plot.\n",
    "    \"\"\"\n",
    "    cmap = mpl.colormaps.get_cmap(cmap)\n",
    "    ax = fig.add_subplot(ax_pos, projection=\"3d\")\n",
    "    x, y, z = pos\n",
    "    if remove_axes_ticks:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "    if label_axes:\n",
    "        ax.set_xlabel(\"$x$ coordinate\")\n",
    "        ax.set_ylabel(\"$y$ coordinate\")\n",
    "        ax.set_zlabel(\"$z$ coordinate\")\n",
    "    \n",
    "    if cbar:\n",
    "        sc = ax.scatter(x, y, z, c=color, cmap=cmap, s=point_size)\n",
    "        plt.colorbar(sc, location=\"bottom\", shrink=0.6, anchor=(0.5, 2), label=cbar_label)\n",
    "                \n",
    "    else:\n",
    "        sc = ax.scatter(x, y, z, color=color, alpha=0.8, s=point_size)\n",
    "        \n",
    "    if annotate_points:\n",
    "        for i, (xi, yi, zi) in enumerate(zip(x, y, z)):\n",
    "            ax.text(xi, yi, zi, annotations[i], None, color='black', fontsize=8, ha=\"center\", va=\"center\")\n",
    "        \n",
    "    return ax\n",
    "\n",
    "\n",
    "# testing\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plt.subplots_adjust(left=0.01, right=0.99, bottom=0.01, top=0.99, wspace=0.01, hspace=0.01)\n",
    "\n",
    "ax_pos = [221, 222, 223, 224]\n",
    "\n",
    "# define color based on atom names\n",
    "atom_names = sorted_isomers_universe.select_atoms('all').atoms.names\n",
    "colors = {'C': 'cyan', 'O': 'red', 'H': 'silver'}\n",
    "atom_colors = []\n",
    "for i in range(atom_names.shape[0]):\n",
    "    atom_colors.append(colors[atom_names[i]])\n",
    "\n",
    "# Visualize first four structures \n",
    "for i, ts in enumerate(sorted_isomers_universe.trajectory[:4]):\n",
    "    \n",
    "    pos = sorted_isomers_universe.select_atoms('all').positions.T\n",
    "    \n",
    "    #color = ['blue']#np.random.rand(pos.shape[1])\n",
    "    color = atom_colors\n",
    "    \n",
    "    plot_point_cloud_3d(fig, ax_pos[i], color, pos, annotations=atom_names, \n",
    "                        annotate_points=True, remove_axes_ticks=False)\n",
    "\n",
    "#fig.suptitle(\"Random test point clouds\")\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7065498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8be020a4",
   "metadata": {},
   "source": [
    "#### Construct the adjacency matrix with atoms as nodes and edges as pairwise distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3609d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DistanceGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_atoms, distance_cutoff):\n",
    "        \n",
    "        super(DistanceGraph, self).__init__()\n",
    "        self.num_atoms = num_atoms\n",
    "        self.num_edges = num_atoms * (num_atoms - 1) // 2\n",
    "        self.distance_cutoff = distance_cutoff\n",
    "        \n",
    "        \n",
    "    def create_edge_index(self):\n",
    "        \n",
    "        edge_index = []\n",
    "        for i in range(self.num_atoms):\n",
    "            for j in range(i+1, self.num_atoms):\n",
    "                edge_index.append([i, j])\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        return edge_index\n",
    "    \n",
    "    def create_edge_index(self):\n",
    "        edge_index = []\n",
    "        edge_distances = []\n",
    "        for i in range(self.num_atoms):\n",
    "            for j in range(i+1, self.num_atoms):\n",
    "                distance = torch.norm(self.positions[i] - self.positions[j]) #ASSUME PBC NOT REQUIRED\n",
    "                #print(distance)\n",
    "                if distance <= self.distance_cutoff:\n",
    "                    edge_index.append([i, j])\n",
    "                    edge_distances.append(distance)\n",
    "                    \n",
    "        #print(edge_index)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_distances = torch.tensor(edge_distances, dtype=torch.float)\n",
    "        return edge_index, edge_distances\n",
    "    \n",
    "    \n",
    "    def forward(self, x, positions, time, y):\n",
    "        \n",
    "        self.x = x\n",
    "        self.positions = positions\n",
    "        self.time = time\n",
    "        self.y=y\n",
    "        \n",
    "        self.edge_index, self.edge_dists = self.create_edge_index()\n",
    "                \n",
    "        edge_attr = self.edge_dists # torch.ones(self.edge_index.size(1), dtype=torch.float) \n",
    "                \n",
    "        data = Data(x=self.x, edge_index=self.edge_index, edge_attr=np.round(edge_attr,2), \n",
    "                    time=self.time, y=self.y)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532b438-fc1c-4140-96f2-fac5d4fd9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_num = []\n",
    "for i in sorted_isomers_universe.atoms.elements:\n",
    "    if i == 'C':\n",
    "        atom_num.append(1)\n",
    "    elif i == 'O':\n",
    "        atom_num.append(0.5)\n",
    "    else:\n",
    "        atom_num.append(0)\n",
    "\n",
    "\n",
    "\n",
    "atom_num = torch.Tensor(atom_num)\n",
    "#atom_masses = torch.Tensor(sorted_isomers_universe.atoms. masses)#.reshape(-1,1)\n",
    "\n",
    "    \n",
    "# Scale input to the range 0 to 1.\n",
    "x_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "x_scaler.fit(sorted_isomers_universe.atoms.masses.reshape(-1, 1))\n",
    "x_scaled = x_scaler.transform(sorted_isomers_universe.atoms.masses.reshape(-1, 1))\n",
    "x_scaled = np.array(x_scaled)\n",
    "\n",
    "#node_features = torch.ones(selection.atoms.n_atoms).reshape(-1,1)\n",
    "#node_features = torch.vstack((atom_num, atom_masses)).T #reshape(-1,2)\n",
    "# node_features = atom_masses.reshape(-1,1)\n",
    "\n",
    "node_features = torch.Tensor(x_scaled).reshape(-1,1)\n",
    "\n",
    "node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca29923",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_graph = DistanceGraph(sorted_isomers_universe.atoms.n_atoms, 1.7)\n",
    "selection = sorted_isomers_universe.select_atoms('all')\n",
    "\n",
    "\n",
    "graph_data_time = []\n",
    "for i, ts in enumerate(sorted_isomers_universe.trajectory):\n",
    "    \n",
    "    positions_tensor = torch.tensor(selection.positions, dtype=torch.float)\n",
    "    graph_data = distance_graph(node_features, positions_tensor, time=ts.time, y=torch.tensor(y_scaled[i], dtype=torch.float32))\n",
    "\n",
    "    graph_data_time.append(graph_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebda976",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_time[6000].x, pbe_energies.energy.values[6000], y_scaled[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f25da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34d6a096-1e80-41b4-939e-670e759f787a",
   "metadata": {},
   "source": [
    "#### plot an example molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40003f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 subplot\n",
    "fig, all_axes = plt.subplots(2, 2)\n",
    "ax = all_axes.flat\n",
    "\n",
    "for i,select_graph in enumerate([1, 10, 100, 1000]):\n",
    "\n",
    "    edge_attr = graph_data_time[select_graph].edge_attr\n",
    "    nx_graph = to_networkx(graph_data_time[select_graph], edge_attrs=[\"edge_attr\"])\n",
    "    pos = nx.spectral_layout(nx_graph, weight='weight')\n",
    "    #pos = nx.spring_layout(nx_graph)\n",
    "    \n",
    "    edge_labels = nx.get_edge_attributes(nx_graph, 'edge_attr')\n",
    "    edge_labels = dict([((u,v,), f\"{d['edge_attr']:.2f}\") for u,v,d in nx_graph.edges(data=True)])\n",
    "    nx.draw(nx_graph, with_labels=True, node_color=atom_colors, ax=ax[i], pos=pos)\n",
    "    # nx.draw_networkx_edge_labels(nx_graph, pos=pos, edge_labels = edge_labels, \n",
    "    #                              font_size=8, verticalalignment='bottom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00a7c7-5446-4ff7-a683-1e069c6bcc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b3e3c46-42d0-4eef-b149-8b39428f5c38",
   "metadata": {},
   "source": [
    "#### Graph convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://projects.volkamerlab.org/teachopencadd/talktorials/T035_graph_neural_networks.html\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU\n",
    "writer = SummaryWriter('./tensorflow_logs')\n",
    "\n",
    "# class GIN(torch.nn.Module):\n",
    "#     \"\"\"Graph Isomorphism Network class with 3 GINConv layers and 2 linear layers\"\"\"\n",
    "\n",
    "#     def __init__(self, input_dim, dim_h, output_dim):\n",
    "#         \"\"\"Initializing GIN class\n",
    "\n",
    "#         Args:\n",
    "#             dim_h (int): the dimension of hidden layers\n",
    "#         \"\"\"\n",
    "#         super(GIN, self).__init__()\n",
    "#         self.conv1 = GINConv(\n",
    "#             Sequential(Linear(input_dim, dim_h), BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h), ReLU())\n",
    "#         )\n",
    "#         self.conv2 = GINConv(\n",
    "#             Sequential(\n",
    "#                 Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
    "#             )\n",
    "#         )\n",
    "#         self.conv3 = GINConv(\n",
    "#             Sequential(\n",
    "#                 Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
    "#             )\n",
    "#         )\n",
    "#         self.lin1 = Linear(dim_h, dim_h)\n",
    "#         self.lin2 = Linear(dim_h, output_dim)\n",
    "\n",
    "#     # def forward(self, data):\n",
    "#     def forward(self, x, edge_index, batch):\n",
    "#         #x = data.x\n",
    "#         #edge_index = data.edge_index\n",
    "#         #batch = data.batch\n",
    "\n",
    "#         # Node embeddings\n",
    "#         h = self.conv1(x, edge_index)\n",
    "#         h = h.relu()\n",
    "#         h = self.conv2(h, edge_index)\n",
    "#         h = h.relu()\n",
    "#         h = self.conv3(h, edge_index)\n",
    "\n",
    "#         # Graph-level readout\n",
    "#         h = global_add_pool(h, batch)\n",
    "\n",
    "#         h = self.lin1(h)\n",
    "#         h = h.relu()\n",
    "#         h = Fun.dropout(h, p=0.5, training=self.training)\n",
    "#         h = self.lin2(h)\n",
    "\n",
    "#         return h\n",
    "\n",
    "\n",
    "\n",
    "#torch.manual_seed(1234567)    \n",
    "# Simple GNN model\n",
    "class GCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim, normalize=True, bias=True)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim, normalize=True, bias=True)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim, normalize=True, bias=True)\n",
    "        self.conv4 = GCNConv(hidden_dim, hidden_dim, normalize=True, bias=True)\n",
    "        self.conv5 = GCNConv(hidden_dim, hidden_dim, normalize=True, bias=True)\n",
    "        \n",
    "        self.lin = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \n",
    "        #x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.tanh()\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.tanh()\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.tanh()\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = x.tanh()\n",
    "\n",
    "        x = self.conv5(x, edge_index)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        # x = global_add_pool(x, batch)\n",
    "        \n",
    "\n",
    "        # x = Fun.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "def training(loader, model, loss, optimizer):\n",
    "    \n",
    "    \"\"\"Training one epoch\n",
    "\n",
    "    Args:\n",
    "        loader (DataLoader): loader (DataLoader): training data divided into batches\n",
    "        model (nn.Module): GNN model to train on\n",
    "        loss (nn.functional): loss function to use during training\n",
    "        optimizer (torch.optim): optimizer during training\n",
    "\n",
    "    Returns:\n",
    "        float: training loss\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    for i, d in enumerate(loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        d.x = d.x.float()\n",
    "        \n",
    "        out = model(d.x, d.edge_index, d.batch)\n",
    "\n",
    "        #if i == 0:\n",
    "        #print(i, out, d.y)\n",
    "        \n",
    "        l = loss(out, torch.reshape(d.y, (len(d.y), 1)))\n",
    "        \n",
    "        current_loss += l / len(loader)\n",
    "        \n",
    "        l.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    return current_loss, model\n",
    "\n",
    "\n",
    "def validation(loader, model, loss):\n",
    "    \"\"\"Validation\n",
    "\n",
    "    Args:\n",
    "        loader (DataLoader): validation set in batches\n",
    "        model (nn.Module): current trained model\n",
    "        loss (nn.functional): loss function\n",
    "\n",
    "    Returns:\n",
    "        float: validation loss\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_target = np.empty((0))\n",
    "    val_y_target = np.empty((0))\n",
    "    for d in loader:\n",
    "        out = model(d.x, d.edge_index, d.batch)\n",
    "        l = loss(out, torch.reshape(d.y, (len(d.y), 1)))\n",
    "        val_loss += l / len(loader)\n",
    "\n",
    "        val_target = np.concatenate((val_target, out.detach().numpy()[:,0]))\n",
    "        val_y_target = np.concatenate((val_y_target, d.y.detach().numpy()))\n",
    "    \n",
    "    return val_loss, val_target, val_y_target\n",
    "    \n",
    "\n",
    "def train_epochs(epochs, model, train_loader, val_loader, path, lr, criterion):\n",
    "    \n",
    "    \"\"\"Training over all epochs\n",
    "\n",
    "    Args:\n",
    "        epochs (int): number of epochs to train for\n",
    "        model (nn.Module): the current model\n",
    "        train_loader (DataLoader): training data in batches\n",
    "        val_loader (DataLoader): validation data in batches\n",
    "        path (string): path to save the best model\n",
    "\n",
    "    Returns:\n",
    "        array: returning train and validation losses over all epochs, prediction and ground truth values for training data in the last epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=lr) #, weight_decay=5e-4)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    loss = criterion\n",
    "\n",
    "    train_target = np.empty((0))\n",
    "    train_y_target = np.empty((0))\n",
    "    train_loss = np.empty(epochs)\n",
    "    val_loss = np.empty(epochs)\n",
    "    val_target = np.empty((0))\n",
    "    val_y_target = np.empty((0))\n",
    "    # best_loss = math.inf\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_loss, model = training(train_loader, model, loss, optimizer)\n",
    "\n",
    "        v_loss, v_target, v_y_target = validation(val_loader, model, loss)\n",
    "        \n",
    "        if epoch == epochs - 1:\n",
    "            val_target = np.concatenate((val_target, v_target))\n",
    "            val_y_target = np.concatenate((val_y_target, v_y_target))\n",
    "        \n",
    "#         if v_loss < best_loss:\n",
    "#             torch.save(model.state_dict(), path)\n",
    "        for d in train_loader:\n",
    "            out = model(d.x, d.edge_index, d.batch)\n",
    "            if epoch == epochs - 1:\n",
    "                # record truly vs predicted values for training data from last epoch\n",
    "                train_target = np.concatenate((train_target, out.detach().numpy()[:, 0]))\n",
    "                train_y_target = np.concatenate((train_y_target, d.y.detach().numpy()))\n",
    "\n",
    "        train_loss[epoch] = epoch_loss.detach().numpy()\n",
    "        val_loss[epoch] = v_loss.detach().numpy()\n",
    "\n",
    "        writer.add_scalar('Loss/train',  train_loss[epoch], epoch)\n",
    "        writer.add_scalar('Loss/validation',  val_loss[epoch], epoch)\n",
    "        weight_histograms(writer, epoch, model)\n",
    "        \n",
    "\n",
    "        # print current train and val loss\n",
    "        if epoch % 2 == 0:\n",
    "            print(\n",
    "                \"Epoch: \"\n",
    "                + str(epoch)\n",
    "                + \", Train loss: \"\n",
    "                + str(epoch_loss.item())\n",
    "                + \", Val loss: \"\n",
    "                + str(v_loss.item())\n",
    "            )\n",
    "            \n",
    "    return train_target, train_y_target, train_loss , val_target, val_y_target, val_loss\n",
    "\n",
    "\n",
    "#https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-tensorboard-with-pytorch.md\n",
    "def weight_histograms_gcc(writer, step, weights, layer_number):\n",
    "  weights_shape = weights.shape\n",
    "  num_kernels = weights_shape[0]\n",
    "  for k in range(num_kernels):\n",
    "    flattened_weights = weights[k].flatten()\n",
    "    tag = f\"layer_{layer_number}/kernel_{k}\"\n",
    "    writer.add_histogram(tag, flattened_weights, global_step=step, bins='tensorflow')\n",
    "\n",
    "\n",
    "def weight_histograms_linear(writer, step, weights, layer_number):\n",
    "  flattened_weights = weights.flatten()\n",
    "  tag = f\"layer_{layer_number}\"\n",
    "  writer.add_histogram(tag, flattened_weights, global_step=step, bins='tensorflow')\n",
    "\n",
    "\n",
    "def weight_histograms(writer, step, model):\n",
    "  #print(\"Visualizing model weights...\")\n",
    "  # Iterate over all model layers\n",
    "  #for layer_number in range(len(model.layers)):\n",
    "  for l, layer in enumerate(model.children()):\n",
    "    # Get layer\n",
    "    # Compute weight histograms for appropriate layer\n",
    "    if isinstance(layer, GCNConv):\n",
    "      weights = layer.get_parameter('lin.weight')\n",
    "      weight_histograms_gcc(writer, step, weights, l)\n",
    "    elif isinstance(layer, nn.Linear):\n",
    "      weights = layer.get_parameter('weight')\n",
    "      weight_histograms_linear(writer, step, weights, l)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346b35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd42453-e313-4db4-bfb2-a38b850e6f43",
   "metadata": {},
   "source": [
    "#### Training, testing and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "# data split\n",
    "data_size = sorted_isomers_universe.trajectory.n_frames\n",
    "train_index = int(data_size * 0.8)\n",
    "test_index = train_index + int(data_size * 0.1)\n",
    "val_index = test_index + int(data_size * 0.1)\n",
    "\n",
    "batch_size=500\n",
    "\n",
    "# datasets into DataLoader\n",
    "train_loader = DataLoader(graph_data_time[0:train_index], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(graph_data_time[train_index:test_index], batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(graph_data_time[test_index:val_index], batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a084d6-b76d-4095-8122-fe4ce001202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset[0].x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c861f7e-34fe-4691-b380-08c8d9131f1b",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eaaa896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.07511501759290695, Val loss: 0.10545264184474945\n",
      "Epoch: 12, Train loss: 0.07480689138174057, Val loss: 0.1096133440732956\n",
      "Epoch: 14, Train loss: 0.07504665851593018, Val loss: 0.10841922461986542\n",
      "Epoch: 16, Train loss: 0.0746966078877449, Val loss: 0.11822077631950378\n",
      "Epoch: 18, Train loss: 0.07453270256519318, Val loss: 0.11044710874557495\n"
     ]
    }
   ],
   "source": [
    "# training GCN for 10 epochs\n",
    "epochs = 20\n",
    "model = GCN(input_dim=1, hidden_dim=64, output_dim=1)\n",
    "# model = GIN(input_dim=1, dim_h=64, output_dim=1)\n",
    "\n",
    "\n",
    "train_values = train_epochs(epochs, model, train_loader, val_loader, \"GCN_model.pt\", lr=0.005, criterion=nn.MSELoss())\n",
    "\n",
    "gcn_train_target, gcn_train_y_target, gcn_train_loss, gcn_val_target, gcn_val_y_target, gcn_val_loss = train_values\n",
    "\n",
    "# Create an instance of the TensorObject class with a variable xi\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "\n",
    "writer.add_graph(model,  [data.x, data.edge_index, data.batch])\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1127d39-ceba-4e3e-8ad8-58209d75f2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d914aa77-31d1-4439-bedf-14d77594fe38",
   "metadata": {},
   "source": [
    "#### Check training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gcn_train_loss, label=\"Train loss (GCN)\")\n",
    "plt.plot(gcn_val_loss, label=\"Val loss (GCN)\")\n",
    "\n",
    "\n",
    "plt.legend(frameon=False, fontsize=12)\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea71a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3adc3c23-9ba0-4188-8b0d-b623ba9a993d",
   "metadata": {},
   "source": [
    "#### Check correlation of true values agains predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253ef41-d2c3-44cc-8b9c-ffe87461dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Obtain test values\n",
    "\n",
    "@torch.no_grad()\n",
    "def testing(loader, model):\n",
    "    \"\"\"Testing\n",
    "\n",
    "    Args:\n",
    "        loader (DataLoader): test dataset\n",
    "        model (nn.Module): trained model\n",
    "\n",
    "    Returns:\n",
    "        float: test loss\n",
    "    \"\"\"\n",
    "    loss = torch.nn.MSELoss()\n",
    "    test_loss = 0\n",
    "    test_target = np.empty((0))\n",
    "    test_y_target = np.empty((0))\n",
    "    for d in loader:\n",
    "        out = model(d.x, d.edge_index, d.batch)\n",
    "        # NOTE\n",
    "        # out = out.view(d.y.size())\n",
    "        l = loss(out, torch.reshape(d.y, (len(d.y), 1)))\n",
    "        test_loss += l / len(loader)\n",
    "\n",
    "        # save prediction vs ground truth values for plotting\n",
    "        test_target = np.concatenate((test_target, out.detach().numpy()[:, 0]))\n",
    "        test_y_target = np.concatenate((test_y_target, d.y.detach().numpy()))\n",
    "\n",
    "    return test_loss, test_target, test_y_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5022719c-6142-411f-ae8f-7159b3ade841",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_test_loss, gcn_test_target, gcn_test_y_target = testing(test_loader, model)\n",
    "\n",
    "print(f'Test loss:{gcn_test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143a206-5d0a-4e66-bb7b-31defc298007",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_val_y_target.shape, gcn_val_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195a4ce",
   "metadata": {},
   "source": [
    "#### Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be9699",
   "metadata": {},
   "source": [
    "#### Parity plot of ground truth and predictions in train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea8847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Adjust spacing\n",
    "plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.25, hspace=0.45)\n",
    "\n",
    "nrows=3\n",
    "ncols=2\n",
    "\n",
    "# Create a 3x3 grid\n",
    "grid = GridSpec(nrows, ncols)\n",
    "\n",
    "ax = plt.subplot(grid[0,0])\n",
    "\n",
    "ax.scatter(gcn_train_y_target, gcn_train_target) #, label=f'R2:{np.round(gcn_train_loss,2)}')\n",
    "ax.plot(gcn_train_y_target, gcn_train_y_target)\n",
    "\n",
    "ax.set_xlabel('True (scaled y)')\n",
    "ax.set_ylabel('Predicted (scaled y)')\n",
    "#ax.legend()\n",
    "\n",
    "ax = plt.subplot(grid[0,1])\n",
    "\n",
    "ax.scatter(gcn_val_y_target, gcn_val_target) #, label=f'R2:{np.round(test_r2,2)}')\n",
    "ax.plot(gcn_val_y_target, gcn_val_y_target)\n",
    "\n",
    "ax.set_xlabel('True (scaled y)')\n",
    "ax.set_ylabel('Predicted (scaled y)')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.subplot(grid[1,0])\n",
    "\n",
    "ax.scatter(y_scaler.inverse_transform(gcn_train_y_target.reshape(-1,1)), \n",
    "           y_scaler.inverse_transform(gcn_train_target.reshape(-1,1)))\n",
    "ax.plot(y_scaler.inverse_transform(gcn_train_y_target.reshape(-1,1)), \n",
    "        y_scaler.inverse_transform(gcn_train_y_target.reshape(-1,1)))\n",
    "\n",
    "ax.set_xlabel('True (eV)')\n",
    "ax.set_ylabel('Predicted (eV)')\n",
    "\n",
    "ax = plt.subplot(grid[1,1])\n",
    "\n",
    "ax.scatter(y_scaler.inverse_transform(gcn_val_y_target.reshape(-1,1)), \n",
    "           y_scaler.inverse_transform(gcn_val_target.reshape(-1,1)))\n",
    "ax.plot(y_scaler.inverse_transform(gcn_val_y_target.reshape(-1,1)), \n",
    "        y_scaler.inverse_transform(gcn_val_y_target.reshape(-1,1)))\n",
    "\n",
    "ax.set_xlabel('True (eV)')\n",
    "ax.set_ylabel('Predicted (eV)')\n",
    "\n",
    "\n",
    "ax = plt.subplot(grid[2,0])\n",
    "\n",
    "ax.scatter(y_scaler.inverse_transform(gcn_test_y_target.reshape(-1,1)), \n",
    "           y_scaler.inverse_transform(gcn_test_target.reshape(-1,1)))\n",
    "ax.plot(y_scaler.inverse_transform(gcn_test_y_target.reshape(-1,1)), \n",
    "        y_scaler.inverse_transform(gcn_test_y_target.reshape(-1,1)))\n",
    "\n",
    "ax.set_xlabel('True (eV)')\n",
    "ax.set_ylabel('Predicted (eV)')\n",
    "\n",
    "ax = plt.subplot(grid[2,1])\n",
    "\n",
    "ax.scatter(y_scaler.inverse_transform(gcn_test_y_target.reshape(-1,1)), \n",
    "           y_scaler.inverse_transform(gcn_test_target.reshape(-1,1)))\n",
    "ax.plot(y_scaler.inverse_transform(gcn_test_y_target.reshape(-1,1)), \n",
    "        y_scaler.inverse_transform(gcn_test_y_target.reshape(-1,1)))\n",
    "\n",
    "ax.set_xlabel('True (eV)')\n",
    "ax.set_ylabel('Predicted (eV)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76afa46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
